{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmoVqwYrlf91",
        "outputId": "699e457f-070e-4a59-a875-8c176bf97fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep  5 07:57:49 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW8970eGltf0",
        "outputId": "80f3432e-afef-41cb-c461-87ac728ded09"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "klUALOrilqIb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\")\n",
        "BATCHSIZE = 128\n",
        "CLASSES = 10\n",
        "DIR = os.getcwd()\n",
        "EPOCHS = 10\n",
        "N_TRAIN_EXAMPLES = BATCHSIZE * 17 #30\n",
        "N_VALID_EXAMPLES = BATCHSIZE * 5  #10"
      ],
      "metadata": {
        "id": "tkJm5e_BlsJm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(trial):\n",
        "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
        "    layers = []\n",
        "\n",
        "    in_features = 28 * 28\n",
        "    for i in range(n_layers):\n",
        "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
        "        layers.append(nn.Linear(in_features, out_features))\n",
        "        layers.append(nn.ReLU())\n",
        "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
        "        layers.append(nn.Dropout(p))\n",
        "\n",
        "        in_features = out_features\n",
        "    layers.append(nn.Linear(in_features, CLASSES))\n",
        "    layers.append(nn.LogSoftmax(dim=1))\n",
        "\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "gjx9zIIbExbu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist():\n",
        "    # Load FashionMNIST dataset.\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "metadata": {
        "id": "t4sdKfFvEzzO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tl, vl = get_mnist()\n",
        "len(tl), len(vl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mdnx76QE35g",
        "outputId": "5a20a73a-ff1c-47d7-a06d-d1a24a85f636"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /content/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 10370264.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/train-images-idx3-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /content/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 176174.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /content/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3234776.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /content/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 6401505.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(469, 79)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "    # attributes = dir(trial)\n",
        "    # print(attributes)\n",
        "\n",
        "    # Generate the model.\n",
        "    model = define_model(trial).to(DEVICE)\n",
        "\n",
        "    # Generate the optimizers.\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "\n",
        "    # Get the FashionMNIST dataset.\n",
        "    train_loader, valid_loader = get_mnist()\n",
        "\n",
        "    # Training of the model.\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            if trial._trial_id and (trial._trial_id % 71 == 0):\n",
        "              print(f'Train -> trial_id : {trial._trial_id} , Epoch num is {epoch}, batch_idx is {batch_idx}, optimizer_name : {optimizer_name}')\n",
        "            # Limiting training data for faster epochs.\n",
        "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
        "                break\n",
        "\n",
        "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation of the model.\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "                # Limiting validation data.\n",
        "                if trial._trial_id and (trial._trial_id % 71 == 0):\n",
        "                    print(f'Valid -> trial_id : {trial._trial_id} , Epoch num is {epoch}, batch_idx is {batch_idx}, optimizer_name : {optimizer_name}')\n",
        "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
        "                    break\n",
        "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "                output = model(data)\n",
        "                # Get the index of the max log-probability.\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
        "\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "NkTiTYj5l0iO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100, timeout=600)\n",
        "\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTtnKBjel2b4",
        "outputId": "35524ca0-094e-4d12-8e46-ac333e7c3560"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-05 08:09:55,140] A new study created in memory with name: no-name-cc824ea0-ecda-4cfe-8720-e85303fb4d80\n",
            "[I 2023-09-05 08:09:59,213] Trial 0 finished with value: 0.6578125 and parameters: {'n_layers': 2, 'n_units_l0': 11, 'dropout_l0': 0.45078537965881454, 'n_units_l1': 101, 'dropout_l1': 0.48197065032968206, 'optimizer': 'RMSprop', 'lr': 0.0008070551054499255}. Best is trial 0 with value: 0.6578125.\n",
            "[I 2023-09-05 08:10:02,357] Trial 1 finished with value: 0.2515625 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'dropout_l0': 0.45940046657759265, 'optimizer': 'Adam', 'lr': 5.8132428790092807e-05}. Best is trial 0 with value: 0.6578125.\n",
            "[I 2023-09-05 08:10:05,673] Trial 2 finished with value: 0.090625 and parameters: {'n_layers': 3, 'n_units_l0': 70, 'dropout_l0': 0.26211540032270503, 'n_units_l1': 30, 'dropout_l1': 0.32345233624046377, 'n_units_l2': 39, 'dropout_l2': 0.46214500004560033, 'optimizer': 'SGD', 'lr': 0.00017222157169568378}. Best is trial 0 with value: 0.6578125.\n",
            "[I 2023-09-05 08:10:09,485] Trial 3 finished with value: 0.1140625 and parameters: {'n_layers': 3, 'n_units_l0': 45, 'dropout_l0': 0.48991126504918175, 'n_units_l1': 5, 'dropout_l1': 0.353419369180897, 'n_units_l2': 45, 'dropout_l2': 0.40187420764449955, 'optimizer': 'RMSprop', 'lr': 0.08869766619057096}. Best is trial 0 with value: 0.6578125.\n",
            "[I 2023-09-05 08:10:13,169] Trial 4 finished with value: 0.2953125 and parameters: {'n_layers': 1, 'n_units_l0': 93, 'dropout_l0': 0.3066574276283555, 'optimizer': 'SGD', 'lr': 0.0008873532969002098}. Best is trial 0 with value: 0.6578125.\n",
            "[I 2023-09-05 08:10:16,418] Trial 5 finished with value: 0.8 and parameters: {'n_layers': 1, 'n_units_l0': 85, 'dropout_l0': 0.3129780642163368, 'optimizer': 'Adam', 'lr': 0.008216512841373893}. Best is trial 5 with value: 0.8.\n",
            "[I 2023-09-05 08:10:19,797] Trial 6 finished with value: 0.396875 and parameters: {'n_layers': 3, 'n_units_l0': 90, 'dropout_l0': 0.2079452537309377, 'n_units_l1': 101, 'dropout_l1': 0.4562694118297161, 'n_units_l2': 47, 'dropout_l2': 0.2550278931679286, 'optimizer': 'Adam', 'lr': 0.05453350818531856}. Best is trial 5 with value: 0.8.\n",
            "[I 2023-09-05 08:10:23,937] Trial 7 finished with value: 0.7671875 and parameters: {'n_layers': 2, 'n_units_l0': 116, 'dropout_l0': 0.43016621016831097, 'n_units_l1': 44, 'dropout_l1': 0.4184094607088299, 'optimizer': 'Adam', 'lr': 0.0009088829233186467}. Best is trial 5 with value: 0.8.\n",
            "[I 2023-09-05 08:10:24,310] Trial 8 pruned. \n",
            "[I 2023-09-05 08:10:24,697] Trial 9 pruned. \n",
            "[I 2023-09-05 08:10:27,964] Trial 10 finished with value: 0.778125 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.385367890951389, 'optimizer': 'RMSprop', 'lr': 0.007482667073924936}. Best is trial 5 with value: 0.8.\n",
            "[I 2023-09-05 08:10:31,235] Trial 11 finished with value: 0.7765625 and parameters: {'n_layers': 1, 'n_units_l0': 124, 'dropout_l0': 0.39422987946602983, 'optimizer': 'RMSprop', 'lr': 0.010043572444677152}. Best is trial 5 with value: 0.8.\n",
            "[I 2023-09-05 08:10:35,238] Trial 12 finished with value: 0.7859375 and parameters: {'n_layers': 1, 'n_units_l0': 105, 'dropout_l0': 0.38341513489101114, 'optimizer': 'RMSprop', 'lr': 0.007682474119543092}. Best is trial 5 with value: 0.8.\n",
            "[I 2023-09-05 08:10:38,667] Trial 13 finished with value: 0.79375 and parameters: {'n_layers': 1, 'n_units_l0': 103, 'dropout_l0': 0.37287918075738, 'optimizer': 'RMSprop', 'lr': 0.005814842381848867}. Best is trial 5 with value: 0.8.\n",
            "[I 2023-09-05 08:10:39,095] Trial 14 pruned. \n",
            "[I 2023-09-05 08:10:42,482] Trial 15 finished with value: 0.7734375 and parameters: {'n_layers': 1, 'n_units_l0': 105, 'dropout_l0': 0.357278830048705, 'optimizer': 'Adam', 'lr': 0.02164546758981189}. Best is trial 5 with value: 0.8.\n",
            "[I 2023-09-05 08:10:46,434] Trial 16 finished with value: 0.7828125 and parameters: {'n_layers': 2, 'n_units_l0': 69, 'dropout_l0': 0.27547007550030433, 'n_units_l1': 68, 'dropout_l1': 0.20225733723269412, 'optimizer': 'RMSprop', 'lr': 0.002614664307975127}. Best is trial 5 with value: 0.8.\n",
            "[I 2023-09-05 08:10:47,881] Trial 17 pruned. \n",
            "[I 2023-09-05 08:10:51,230] Trial 18 finished with value: 0.7890625 and parameters: {'n_layers': 1, 'n_units_l0': 108, 'dropout_l0': 0.4158872765823253, 'optimizer': 'Adam', 'lr': 0.0027845603064423716}. Best is trial 5 with value: 0.8.\n",
            "[I 2023-09-05 08:10:51,659] Trial 19 pruned. \n",
            "[I 2023-09-05 08:10:52,072] Trial 20 pruned. \n",
            "[I 2023-09-05 08:10:55,387] Trial 21 finished with value: 0.815625 and parameters: {'n_layers': 1, 'n_units_l0': 106, 'dropout_l0': 0.4142843795559111, 'optimizer': 'Adam', 'lr': 0.003463051533001695}. Best is trial 21 with value: 0.815625.\n",
            "[I 2023-09-05 08:10:59,020] Trial 22 finished with value: 0.7953125 and parameters: {'n_layers': 1, 'n_units_l0': 94, 'dropout_l0': 0.36753399434512046, 'optimizer': 'Adam', 'lr': 0.0021894095201007}. Best is trial 21 with value: 0.815625.\n",
            "[I 2023-09-05 08:11:02,836] Trial 23 finished with value: 0.7984375 and parameters: {'n_layers': 1, 'n_units_l0': 95, 'dropout_l0': 0.3984756329016097, 'optimizer': 'Adam', 'lr': 0.002032640150422956}. Best is trial 21 with value: 0.815625.\n",
            "[I 2023-09-05 08:11:03,570] Trial 24 pruned. \n",
            "[I 2023-09-05 08:11:04,317] Trial 25 pruned. \n",
            "[I 2023-09-05 08:11:07,581] Trial 26 finished with value: 0.809375 and parameters: {'n_layers': 1, 'n_units_l0': 115, 'dropout_l0': 0.4308097417308946, 'optimizer': 'Adam', 'lr': 0.005490214398507522}. Best is trial 21 with value: 0.815625.\n",
            "[I 2023-09-05 08:11:08,306] Trial 27 pruned. \n",
            "[I 2023-09-05 08:11:09,074] Trial 28 pruned. \n",
            "[I 2023-09-05 08:11:13,381] Trial 29 finished with value: 0.8 and parameters: {'n_layers': 2, 'n_units_l0': 114, 'dropout_l0': 0.42621141572168114, 'n_units_l1': 86, 'dropout_l1': 0.26510980059461403, 'optimizer': 'Adam', 'lr': 0.004950868459155351}. Best is trial 21 with value: 0.815625.\n",
            "[I 2023-09-05 08:11:14,121] Trial 30 pruned. \n",
            "[I 2023-09-05 08:11:14,567] Trial 31 pruned. \n",
            "[I 2023-09-05 08:11:15,387] Trial 32 pruned. \n",
            "[I 2023-09-05 08:11:16,153] Trial 33 pruned. \n",
            "[I 2023-09-05 08:11:16,594] Trial 34 pruned. \n",
            "[I 2023-09-05 08:11:17,021] Trial 35 pruned. \n",
            "[I 2023-09-05 08:11:17,731] Trial 36 pruned. \n",
            "[I 2023-09-05 08:11:18,168] Trial 37 pruned. \n",
            "[I 2023-09-05 08:11:18,565] Trial 38 pruned. \n",
            "[I 2023-09-05 08:11:18,983] Trial 39 pruned. \n",
            "[I 2023-09-05 08:11:19,426] Trial 40 pruned. \n",
            "[I 2023-09-05 08:11:20,167] Trial 41 pruned. \n",
            "[I 2023-09-05 08:11:23,773] Trial 42 finished with value: 0.834375 and parameters: {'n_layers': 1, 'n_units_l0': 95, 'dropout_l0': 0.3896673092441314, 'optimizer': 'Adam', 'lr': 0.0018814524427726207}. Best is trial 42 with value: 0.834375.\n",
            "[I 2023-09-05 08:11:24,377] Trial 43 pruned. \n",
            "[I 2023-09-05 08:11:28,053] Trial 44 finished with value: 0.8359375 and parameters: {'n_layers': 1, 'n_units_l0': 122, 'dropout_l0': 0.38319467640417193, 'optimizer': 'Adam', 'lr': 0.005301013995922274}. Best is trial 44 with value: 0.8359375.\n",
            "[I 2023-09-05 08:11:31,368] Trial 45 finished with value: 0.7765625 and parameters: {'n_layers': 1, 'n_units_l0': 124, 'dropout_l0': 0.3747171850735085, 'optimizer': 'Adam', 'lr': 0.007391075035520831}. Best is trial 44 with value: 0.8359375.\n",
            "[I 2023-09-05 08:11:32,096] Trial 46 pruned. \n",
            "[I 2023-09-05 08:11:32,522] Trial 47 pruned. \n",
            "[I 2023-09-05 08:11:36,083] Trial 48 finished with value: 0.8125 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.3283384137994054, 'optimizer': 'Adam', 'lr': 0.012005020911447943}. Best is trial 44 with value: 0.8359375.\n",
            "[I 2023-09-05 08:11:37,187] Trial 49 pruned. \n",
            "[I 2023-09-05 08:11:40,807] Trial 50 finished with value: 0.828125 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.37582242834700447, 'optimizer': 'RMSprop', 'lr': 0.001145082395668922}. Best is trial 44 with value: 0.8359375.\n",
            "[I 2023-09-05 08:11:41,210] Trial 51 pruned. \n",
            "[I 2023-09-05 08:11:41,954] Trial 52 pruned. \n",
            "[I 2023-09-05 08:11:45,182] Trial 53 finished with value: 0.778125 and parameters: {'n_layers': 1, 'n_units_l0': 121, 'dropout_l0': 0.39547789420413726, 'optimizer': 'RMSprop', 'lr': 0.002733517618792385}. Best is trial 44 with value: 0.8359375.\n",
            "[I 2023-09-05 08:11:46,556] Trial 54 pruned. \n",
            "[I 2023-09-05 08:11:46,967] Trial 55 pruned. \n",
            "[I 2023-09-05 08:11:50,891] Trial 56 pruned. \n",
            "[I 2023-09-05 08:11:54,159] Trial 57 finished with value: 0.7890625 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.3567079306478776, 'optimizer': 'RMSprop', 'lr': 0.003868563756947816}. Best is trial 44 with value: 0.8359375.\n",
            "[I 2023-09-05 08:11:57,496] Trial 58 finished with value: 0.771875 and parameters: {'n_layers': 1, 'n_units_l0': 106, 'dropout_l0': 0.375744277374829, 'optimizer': 'Adam', 'lr': 0.010066128105430701}. Best is trial 44 with value: 0.8359375.\n",
            "[I 2023-09-05 08:11:57,917] Trial 59 pruned. \n",
            "[I 2023-09-05 08:11:58,333] Trial 60 pruned. \n",
            "[I 2023-09-05 08:11:58,761] Trial 61 pruned. \n",
            "[I 2023-09-05 08:11:59,184] Trial 62 pruned. \n",
            "[I 2023-09-05 08:12:00,266] Trial 63 pruned. \n",
            "[I 2023-09-05 08:12:03,208] Trial 64 pruned. \n",
            "[I 2023-09-05 08:12:03,632] Trial 65 pruned. \n",
            "[I 2023-09-05 08:12:04,052] Trial 66 pruned. \n",
            "[I 2023-09-05 08:12:04,467] Trial 67 pruned. \n",
            "[I 2023-09-05 08:12:05,214] Trial 68 pruned. \n",
            "[I 2023-09-05 08:12:08,583] Trial 69 finished with value: 0.790625 and parameters: {'n_layers': 1, 'n_units_l0': 84, 'dropout_l0': 0.38249957112497784, 'optimizer': 'Adam', 'lr': 0.01776137002432653}. Best is trial 44 with value: 0.8359375.\n",
            "[I 2023-09-05 08:12:11,908] Trial 70 finished with value: 0.8171875 and parameters: {'n_layers': 1, 'n_units_l0': 93, 'dropout_l0': 0.30591000706197236, 'optimizer': 'Adam', 'lr': 0.004681257734486299}. Best is trial 44 with value: 0.8359375.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 0, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 1, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 2, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 3, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 4, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 5, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 6, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 7, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 8, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 9, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 10, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 11, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 12, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 13, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 14, optimizer_name : Adam\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-05 08:12:12,338] Trial 71 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 15, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 16, optimizer_name : Adam\n",
            "Train -> trial_id : 71 , Epoch num is 0, batch_idx is 17, optimizer_name : Adam\n",
            "Valid -> trial_id : 71 , Epoch num is 0, batch_idx is 0, optimizer_name : Adam\n",
            "Valid -> trial_id : 71 , Epoch num is 0, batch_idx is 1, optimizer_name : Adam\n",
            "Valid -> trial_id : 71 , Epoch num is 0, batch_idx is 2, optimizer_name : Adam\n",
            "Valid -> trial_id : 71 , Epoch num is 0, batch_idx is 3, optimizer_name : Adam\n",
            "Valid -> trial_id : 71 , Epoch num is 0, batch_idx is 4, optimizer_name : Adam\n",
            "Valid -> trial_id : 71 , Epoch num is 0, batch_idx is 5, optimizer_name : Adam\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-05 08:12:12,755] Trial 72 pruned. \n",
            "[I 2023-09-05 08:12:13,830] Trial 73 pruned. \n",
            "[I 2023-09-05 08:12:14,421] Trial 74 pruned. \n",
            "[I 2023-09-05 08:12:15,111] Trial 75 pruned. \n",
            "[I 2023-09-05 08:12:18,439] Trial 76 finished with value: 0.81875 and parameters: {'n_layers': 1, 'n_units_l0': 121, 'dropout_l0': 0.34031963460766895, 'optimizer': 'Adam', 'lr': 0.0053523417508515555}. Best is trial 44 with value: 0.8359375.\n",
            "[I 2023-09-05 08:12:18,848] Trial 77 pruned. \n",
            "[I 2023-09-05 08:12:19,246] Trial 78 pruned. \n",
            "[I 2023-09-05 08:12:22,533] Trial 79 finished with value: 0.8421875 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'dropout_l0': 0.35561382482302195, 'optimizer': 'Adam', 'lr': 0.00853671255922034}. Best is trial 79 with value: 0.8421875.\n",
            "[I 2023-09-05 08:12:23,245] Trial 80 pruned. \n",
            "[I 2023-09-05 08:12:23,976] Trial 81 pruned. \n",
            "[I 2023-09-05 08:12:28,172] Trial 82 finished with value: 0.853125 and parameters: {'n_layers': 1, 'n_units_l0': 106, 'dropout_l0': 0.36934243549622037, 'optimizer': 'Adam', 'lr': 0.003344732088224441}. Best is trial 82 with value: 0.853125.\n",
            "[I 2023-09-05 08:12:29,243] Trial 83 pruned. \n",
            "[I 2023-09-05 08:12:29,991] Trial 84 pruned. \n",
            "[I 2023-09-05 08:12:30,408] Trial 85 pruned. \n",
            "[I 2023-09-05 08:12:30,820] Trial 86 pruned. \n",
            "[I 2023-09-05 08:12:31,228] Trial 87 pruned. \n",
            "[I 2023-09-05 08:12:31,653] Trial 88 pruned. \n",
            "[I 2023-09-05 08:12:32,397] Trial 89 pruned. \n",
            "[I 2023-09-05 08:12:32,820] Trial 90 pruned. \n",
            "[I 2023-09-05 08:12:36,166] Trial 91 finished with value: 0.80625 and parameters: {'n_layers': 1, 'n_units_l0': 117, 'dropout_l0': 0.3786907001370604, 'optimizer': 'Adam', 'lr': 0.00836730933123969}. Best is trial 82 with value: 0.853125.\n",
            "[I 2023-09-05 08:12:40,386] Trial 92 finished with value: 0.8171875 and parameters: {'n_layers': 1, 'n_units_l0': 122, 'dropout_l0': 0.39657624839089645, 'optimizer': 'Adam', 'lr': 0.005653309525060541}. Best is trial 82 with value: 0.853125.\n",
            "[I 2023-09-05 08:12:43,767] Trial 93 finished with value: 0.803125 and parameters: {'n_layers': 1, 'n_units_l0': 125, 'dropout_l0': 0.3985341941519526, 'optimizer': 'Adam', 'lr': 0.006575135828719097}. Best is trial 82 with value: 0.853125.\n",
            "[I 2023-09-05 08:12:45,486] Trial 94 pruned. \n",
            "[I 2023-09-05 08:12:46,229] Trial 95 pruned. \n",
            "[I 2023-09-05 08:12:46,634] Trial 96 pruned. \n",
            "[I 2023-09-05 08:12:47,365] Trial 97 pruned. \n",
            "[I 2023-09-05 08:12:48,108] Trial 98 pruned. \n",
            "[I 2023-09-05 08:12:52,083] Trial 99 finished with value: 0.771875 and parameters: {'n_layers': 1, 'n_units_l0': 123, 'dropout_l0': 0.35979802610875605, 'optimizer': 'Adam', 'lr': 0.013570398134665962}. Best is trial 82 with value: 0.853125.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  100\n",
            "  Number of pruned trials:  63\n",
            "  Number of complete trials:  37\n",
            "Best trial:\n",
            "  Value:  0.853125\n",
            "  Params: \n",
            "    n_layers: 1\n",
            "    n_units_l0: 106\n",
            "    dropout_l0: 0.36934243549622037\n",
            "    optimizer: Adam\n",
            "    lr: 0.003344732088224441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2U8e9WnGEt3h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}